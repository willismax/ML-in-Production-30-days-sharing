---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.15.1
  kernelspec:
    display_name: Python 3
    name: python3
---

<!-- #region id="view-in-github" colab_type="text" -->
<a href="https://colab.research.google.com/github/willismax/ML-in-Production-30-days-sharing/blob/main/notebook/17.%E7%89%B9%E5%BE%B5%E9%81%B8%E6%93%87_Deta_Selection_%E9%90%B5%E4%BA%BA%E8%B3%BD%E7%A4%BA%E7%AF%84_.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
<!-- #endregion -->

<!-- #region id="aXi3dcBeI0RG" -->
# 特徵選擇
<!-- #endregion -->

<!-- #region id="0OY8eQKaLcuu" -->
- 此為[ithome鐵人賽 Day17](https://ithelp.ithome.com.tw/articles/10264846)程式實作範例，資料集為經整理過後較簡易的[鐵達尼號資料集](https://raw.githubusercontent.com/duxuhao/Feature-Selection/master/example/titanic/clean_train.csv)，Model主要以`sklearn.ensemble.RandomForestClassifier`進行示範，程式碼參考[Machine Learning Data Lifecycle in Production](https://www.coursera.org/learn/machine-learning-data-lifecycle-in-production)課程，它是[Machine Learning Engineering for Production (MLOps) 專項課程](https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops)其中一部分。
<!-- #endregion -->

<!-- #region id="RNh2UtZtNaBn" -->
## 下載及整理資料
<!-- #endregion -->

```python id="I9_O6c_BfaaK"
import pandas as pd
import numpy as np

from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFE, SelectKBest, SelectFromModel, chi2, f_classif
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score
from sklearn.svm import LinearSVC
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import StandardScaler, MinMaxScaler

import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt
```

```python id="9M-AmPMEg8f1" colab={"base_uri": "https://localhost:8080/"} outputId="8cae813f-bec7-4e7c-fe10-c4b91b3fabc6"
# 下載鐵達尼號資料集
!wget -O data.csv https://raw.githubusercontent.com/duxuhao/Feature-Selection/master/example/titanic/clean_train.csv
```

```python colab={"base_uri": "https://localhost:8080/", "height": 458} id="U7I98NsTfl61" outputId="66dab21f-91a1-4912-b49b-4cd34c8cac68"
df = pd.read_csv('data.csv')
df.describe(include='all')
```

```python colab={"base_uri": "https://localhost:8080/"} id="Fn_I71dPjLzz" outputId="5fc2a5b5-a6da-45ad-f79a-b915da30726a"
# 確認有無缺失值
df.isna().sum()
```

```python id="Py961eVPl_31" colab={"base_uri": "https://localhost:8080/"} outputId="2a2089ab-615b-467d-a519-c8e249ff3690"
# 特徵工程 (One-hot encoding)
df = pd.concat(
    [df,pd.get_dummies(df["Title"])], 
    axis=1
    )
df = df.drop("Title", 1)
```

```python id="1-VSmat5lWLg" colab={"base_uri": "https://localhost:8080/"} outputId="90366ca3-8f33-4cbf-e425-179f2212b350"
# 切分特徵X與標籤Y
X = df.drop("Survived", 1)
Y = df["Survived"]
```

```python colab={"base_uri": "https://localhost:8080/", "height": 206} id="6_dxMV_llzaL" outputId="455f20ed-2560-4975-ae92-0bda72e3b0f1"
X.head()
```

<!-- #region id="YCm5wr9rQeQm" -->
## 定義評估模型
<!-- #endregion -->

<!-- #region id="czOmOBAOQhSG" -->
- 本範例採具有階層性的`sklearn.ensemble.RandomForestClassifier`訓練資料，評估結果為驗證資料集的metrics。
<!-- #endregion -->

```python id="UXuQpVEN1F9j"
def use_RandomForestClassifier_evaluation_metrics_on_test_set(X,Y):
    X_train, X_test, Y_train, Y_test = train_test_split(
        X, Y, test_size = 0.2 ,stratify=Y, random_state = 9527)

    # 標準化
    scaler = StandardScaler().fit(X_train)
    X_train_scaled = scaler.transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # RandomForestClassifier訓練模型
    model = RandomForestClassifier(criterion='entropy', random_state=9527)
    model.fit(X_train_scaled, Y_train)

    # 預測
    y_predict_result = model.predict(X_test_scaled)

    # 回傳evaluation_metrics_on_test_set
    return {
        'accuracy' : accuracy_score(Y_test, y_predict_result),
        'roc' : roc_auc_score(Y_test, y_predict_result),
        'precision' : precision_score(Y_test, y_predict_result),
        'recall' : recall_score(Y_test, y_predict_result),
        'f1' : f1_score(Y_test, y_predict_result),
        'Feature Count' : len(X.columns)
        }
```

<!-- #region id="Apte56gWRRvN" -->
### 全特徵原始成效
<!-- #endregion -->

```python colab={"base_uri": "https://localhost:8080/", "height": 81} id="0LJVcjm_3m6D" outputId="e5daaf02-aded-4542-8fef-479f822f3265"
res = pd.DataFrame(use_RandomForestClassifier_evaluation_metrics_on_test_set(X,Y), index=['ALL'])
res
```

```python colab={"base_uri": "https://localhost:8080/", "height": 924} id="F25ffHzF7voO" outputId="ade4808b-03e4-41f4-a39d-97308ef901fc"
# Correlation Matrix
plt.figure(figsize=(15,15))
cor = df.corr() 
sns.heatmap(cor, annot=True)
plt.show()
```

<!-- #region id="TTXqokfKT2vs" -->
## 過濾方法 Filter Method
<!-- #endregion -->

<!-- #region id="1Dh1wbOyRf6w" -->
### 依關聯性移除特徵
<!-- #endregion -->

```python colab={"base_uri": "https://localhost:8080/"} id="oNL87FcE73t7" outputId="de9c0466-5c9e-487b-9148-98898a5d6fbe"
# 取得具有與其他部分特徵高度相關的某特徵絕對值
cor_target = abs(cor["FamilySize"])

# 選擇高度相關的特徵（閾值 = 0.2）
relevant_features = cor_target[cor_target>0.2]

# 選擇特徵名稱
names = [index for index, value in relevant_features.iteritems()]

# 刪除目標特徵
names.remove('FamilySize')

print(names)
```

```python colab={"base_uri": "https://localhost:8080/", "height": 112} id="ko7QguiG8zEz" outputId="f76137bf-7f74-4e24-ece7-e9577faa5147"
res = res.append(
    pd.DataFrame(
        use_RandomForestClassifier_evaluation_metrics_on_test_set(
            X[names],
            Y), 
            index=['Remove High Corr']))
res
```

```python colab={"base_uri": "https://localhost:8080/", "height": 868} id="gt6FFMwE9FxX" outputId="47605536-b9cc-4fa6-89c8-450c221affe1"
# Correlation Matrix
plt.figure(figsize=(15,15))
cor = X[names].corr() 
sns.heatmap(cor, annot=True,)
plt.show()
```

<!-- #region id="2kkrx8jZTsWs" -->
### 單變量特徵選取 Univariate Selection
<!-- #endregion -->

```python id="9ryoZoef907J"
def univariate_selection(X, Y, k=10):
    
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify=Y, random_state = 9527)
    
    scaler = StandardScaler().fit(X_train)
    X_train_scaled = scaler.transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # User SelectKBest to select top 10 features based on f-test
    selector = SelectKBest(f_classif)
    X_new = selector.fit_transform(X_train_scaled, Y_train)

    feature_idx = selector.get_support()

    feature_names = X.columns[feature_idx]
    
    return feature_names
```

```python colab={"base_uri": "https://localhost:8080/"} id="Qk5xeqh3-6M7" outputId="622f7fd3-c4d7-41ca-dbfd-120294038e97"
univariate_selection(X,Y)
```

```python colab={"base_uri": "https://localhost:8080/", "height": 143} id="btj_fjvh_AgV" outputId="cc47ce09-6d60-46cf-9f6b-06b0819b6e4f"
res = res.append(
    pd.DataFrame(
        use_RandomForestClassifier_evaluation_metrics_on_test_set(
            X[univariate_selection(X,Y)],
            Y), 
            index=['Univariate Selection']))
res
```

<!-- #region id="KOxphhEzT9jy" -->
## 包裝方法 Wrapper Method
<!-- #endregion -->

<!-- #region id="apTwOvp_A6Ff" -->
### 遞迴特徵消除 Recursive feature elimination (RFE)
<!-- #endregion -->

```python id="pWq1YFviAXAG"
# Recursive Feature Elimination
def rfe_selection( X , Y, k=10):
    
    # Split train and test sets
    X_train, X_test, Y_train, Y_test = train_test_split(
        X, 
        Y, 
        test_size = 0.2, 
        stratify=Y, 
        random_state = 9527)
    
    scaler = StandardScaler().fit(X_train)
    X_train_scaled = scaler.transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    model = RandomForestClassifier(
        criterion='entropy', 
        random_state=9527
        )
    rfe = RFE(model)
    rfe = rfe.fit(X_train_scaled, Y_train)

    feature_names = X.columns[rfe.get_support()]
    
    return feature_names

```

```python colab={"base_uri": "https://localhost:8080/"} id="NmYu5pDLBivj" outputId="a143d8ec-c516-4082-af04-26ed7157d958"
rfe_selection(X,Y,10)
```

```python colab={"base_uri": "https://localhost:8080/", "height": 175} id="4lVRX8U2B1yF" outputId="d17983f8-3227-499e-aab3-cb1c94d6bcaf"
res = res.append(
    pd.DataFrame(
        use_RandomForestClassifier_evaluation_metrics_on_test_set(
            X[rfe_selection(X,Y)],
            Y), 
            index=['RFE']))

res
```

<!-- #region id="sE0oIcfTUSpj" -->
## 嵌入方法 Embedded Method
<!-- #endregion -->

<!-- #region id="iX0QjpxtCeVI" -->
### 重要特徵 Feature importance
<!-- #endregion -->

```python id="QjElP8WYCQg2"
def feature_importance(X,Y):
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2,stratify=Y, random_state = 9527)
    
    scaler = StandardScaler().fit(X_train)
    X_train_scaled = scaler.transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    model = RandomForestClassifier()
    model = model.fit(X_train_scaled,Y_train)

    plt.figure(figsize=(10, 12))
    feat_importances = pd.Series(model.feature_importances_, index=X.columns)
    feat_importances.sort_values().plot(kind='barh')

    plt.show()
    return model


def select_features_from_model(model,X):
    
    model = SelectFromModel(model, prefit=True, threshold=0.013)
    feature_idx = model.get_support()
    feature_names = X.columns[feature_idx]
        
    return feature_names

```

```python colab={"base_uri": "https://localhost:8080/", "height": 700} id="nA8G5iHDGcjJ" outputId="835642da-964d-4dac-f49d-d2fafd94c7b7"
model = feature_importance(X,Y)
feature_imp_feature_names = select_features_from_model(model,X)
```

```python colab={"base_uri": "https://localhost:8080/"} id="ppsg-Ja3G8E8" outputId="96e92290-1c75-4855-d494-887af67c7b30"
feature_imp_feature_names
```

```python colab={"base_uri": "https://localhost:8080/", "height": 206} id="HSn_wJJEEGN6" outputId="df29ca1c-35a7-4810-d84b-5be45a1e3316"
res = res.append(
    pd.DataFrame(
        use_RandomForestClassifier_evaluation_metrics_on_test_set(
            X[feature_imp_feature_names],
            Y), 
            index=['Feature Importance']))
res
```

<!-- #region id="aMC6hGs_UexA" -->
### L1正規化 L1 regularization
<!-- #endregion -->

```python id="DPiC73GwG4qz" colab={"base_uri": "https://localhost:8080/"} outputId="599d89e0-ba2d-4bf7-c961-f913cc26bd0c"
def run_l1_regularization(X,Y):
    
    # Split train and test set
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2,stratify=Y, random_state = 123)
    
    # All features of dataset are float values. You normalize all features of the train and test dataset here.
    scaler = StandardScaler().fit(X_train)
    X_train_scaled = scaler.transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Select L1 regulated features from LinearSVC output 
    selection = SelectFromModel(LinearSVC(C=1, penalty='l1', dual=False))
    selection.fit(X_train_scaled, Y_train)

    feature_names = X.columns[(selection.get_support())]
    
    return feature_names

l1reg_feature_names = run_l1_regularization(X,Y)
```

```python colab={"base_uri": "https://localhost:8080/", "height": 292} id="jWrE9hoRH6QS" outputId="2fd81e47-8ff7-45bb-c73e-f699b08ec6fd"
res = res.append(
    pd.DataFrame(
        use_RandomForestClassifier_evaluation_metrics_on_test_set(
            X[run_l1_regularization(X,Y)],
            Y), 
            index=['L1']))
res
```

<!-- #region id="ZSivZzbEUsnr" -->
## 評估小結
<!-- #endregion -->

```python colab={"base_uri": "https://localhost:8080/", "height": 261} id="hQzO3NJPO1DA" outputId="ca3beada-33e4-45c1-9f70-d241aeeac20c"
final_res = pd.DataFrame(use_RandomForestClassifier_evaluation_metrics_on_test_set(X,Y), index=['ALL'])
final_res = final_res.append(pd.DataFrame(use_RandomForestClassifier_evaluation_metrics_on_test_set(X[names],Y), index=['Remove High Corr']))
final_res = final_res.append(pd.DataFrame(use_RandomForestClassifier_evaluation_metrics_on_test_set(X[univariate_selection(X,Y)],Y), index=['Univariate Selection']))
final_res = final_res.append(pd.DataFrame(use_RandomForestClassifier_evaluation_metrics_on_test_set(X[rfe_selection(X,Y)],Y), index=['RFE']))
final_res = final_res.append(pd.DataFrame(use_RandomForestClassifier_evaluation_metrics_on_test_set(X[run_l1_regularization(X,Y)],Y), index=['L1']))
final_res.sort_values('accuracy', ascending=False)
```

<!-- #region id="RuMksj9IMuHi" -->
## 參考

<!-- #endregion -->

<!-- #region id="IGJsfvo7VUxU" -->
- [鐵達尼號資料集](https://raw.githubusercontent.com/duxuhao/Feature-Selection/master/example/titanic/clean_train.csv)
- [Machine Learning Data Lifecycle in Production](https://www.coursera.org/learn/machine-learning-data-lifecycle-in-production)
- [Machine Learning Engineering for Production (MLOps) 專項課程](https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops)
<!-- #endregion -->
