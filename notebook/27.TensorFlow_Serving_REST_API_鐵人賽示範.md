---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.15.1
  kernelspec:
    display_name: Python 3
    name: python3
---

<!-- #region id="view-in-github" colab_type="text" -->
<a href="https://colab.research.google.com/github/willismax/ML-in-Production-30-days-sharing/blob/main/notebook/27.TensorFlow_Serving_REST_API_%E9%90%B5%E4%BA%BA%E8%B3%BD%E7%A4%BA%E7%AF%84.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
<!-- #endregion -->

<!-- #region id="S5nn0mY2yE2m" -->
#  TensorFlow Serving REST API - 鐵人賽示範
<!-- #endregion -->

<!-- #region id="lb-_tS0KySku" -->
- 本篇為[鐵人賽](https://ithelp.ithome.com.tw/articles/10272257)示範，參考[官方範例](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple)修改而成。
- 本篇適用在 Colab 環境。
<!-- #endregion -->

<!-- #region id="XoFq6Ldy1wg4" -->
## 下載資料及訓練模型
<!-- #endregion -->

<!-- #region id="_k1qMmG813Lr" -->
- 由於重點在如何起一個TF Severing 服務，資料採用`keras.datasets.cifar10`進行示範，[CIFAR10](https://keras.io/api/datasets/cifar10/)為小型的影像分類資料集，具有50,000筆訓練資料集與10,000筆測試資料集，皆為32X32像素圖片。更多資訊參閱[官方介紹](https://www.cs.toronto.edu/~kriz/cifar.html)。
<!-- #endregion -->

<!-- #region id="9aHO4au43WsH" -->

|Label| Description|
|-|-|
| 0 | airplane |
| 1 | automobile |
| 2 | bird |
| 3 | cat |
| 4 | deer |
| 5 | dog |
| 6 | frog |
| 7 | horse |
| 8 | ship |
| 9 | truck |
<!-- #endregion -->

```python id="dzLKpmZICaWN"
# TensorFlow and tf.keras
# !pip install -Uq grpcio==1.26.0

import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import os
import subprocess
```

<!-- #region id="5jAk1ZXqTJqN" -->
- 建立模型
<!-- #endregion -->

```python id="7MqDQO0KCaWS" colab={"base_uri": "https://localhost:8080/"} outputId="b88fbfeb-8815-4d3c-da2d-2fc9b0554649"
fashion_mnist = keras.datasets.cifar10
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

# scale the values to 0.0 to 1.0
train_images = train_images / 255.0
test_images = test_images / 255.0

# reshape for feeding into the model
train_images = train_images.reshape(train_images.shape[0], 32, 32, 3)
test_images = test_images.reshape(test_images.shape[0], 32, 32, 3)

class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']


print(f'train_images.shape: {train_images.shape}, of {train_images.dtype}')
print(f'test_images.shape: {test_images.shape}, of {test_images.dtype}')
```

<!-- #region id="PDu7OX8Nf5PY" -->
- 訓練與評估模型
<!-- #endregion -->

```python id="LTNN0ANGgA36" colab={"base_uri": "https://localhost:8080/"} outputId="7e851cf5-c39a-45e5-b151-259172f9071e"
model = keras.Sequential([
  keras.layers.Conv2D(
      input_shape=(32,32,3), 
      filters=8, 
      kernel_size=3, 
      strides=2, 
      activation='relu', 
      name='Conv1'),
  keras.layers.Flatten(),
  keras.layers.Dense(10, name='Dense')
])
model.summary()

testing = False
epochs = 5

model.compile(
    optimizer='adam', 
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=[keras.metrics.SparseCategoricalAccuracy()]
    )
model.fit(train_images, train_labels, epochs=epochs)

test_loss, test_acc = model.evaluate(test_images, test_labels)
print(f'Test accuracy: {test_acc}')
```

<!-- #region id="ox5jCIiEAzwm" -->
### 儲存模型
<!-- #endregion -->

<!-- #region id="AiYfSF8wA2ZV" -->
- 將模型保存為[SavedModel](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/saved_model)格式，以便將模型加載到 TensorFlow Serving 中。
- [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)允許我們在發出推理請求時選擇要使用的模型版本或“可服務”版本。每個版本將導出到給定路徑下的不同子目錄。為此，需在目錄創建 protobuf 文件，並將包含一個版本號。 
- 以下會在`/tmp/`建立版次版次`version = 1`之相關檔案。
<!-- #endregion -->

```python id="0w5Rq8SsgWE6" colab={"base_uri": "https://localhost:8080/"} outputId="c3659b46-0cdb-4250-d84f-808b01f41e69"
import tempfile

MODEL_DIR = tempfile.gettempdir()
version = 1
export_path = os.path.join(MODEL_DIR, str(version))
print(f'export_path = {export_path}')

tf.keras.models.save_model(
    model,
    export_path,
    overwrite=True,
    include_optimizer=True,
    save_format=None,
    signatures=None,
    options=None
)

print('\nSaved model:')
!ls -l {export_path}
```

<!-- #region id="Z2eQZCmQEWw9" -->
### 檢查我們的Saved model
<!-- #endregion -->

<!-- #region id="ECeTIcFoEl8A" -->
- `saved_model_cli` 可以檢查前述[SavedModel](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/MetaGraphDef)中相關資訊，這對理解模型相當有用，包含:
  - [MetaGraphDefs](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/MetaGraphDef)（模型）
  - [SignatureDefs](https://www.tensorflow.org/tfx/tutorials/signature_defs)（您可以調用的方法）
- SavedModel CLI的詳細說明可參閱[TensorFlow 指南](https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#cli-to-inspect-and-execute-savedmodel)。
<!-- #endregion -->

```python id="LU4GDF_aYtfQ" colab={"base_uri": "https://localhost:8080/"} outputId="1660f31e-964c-4c1f-accc-38bf33429400"
!saved_model_cli show --dir {export_path} --all
```

<!-- #region id="B5qXLbmOIgRf" -->
### 建立 TensorFlow Serving 服務 

<!-- #endregion -->

<!-- #region id="HqMykfnmItE0" -->
- 依官方範例此為Colab環境所需設定內容，如使用本機端的 Notebook ，請注意相關提醒。
<!-- #endregion -->

<!-- #region id="bN0tft65JF9s" -->
#### Add TensorFlow Serving distribution URI as a package source
<!-- #endregion -->

<!-- #region id="GE_sVx3MIi9S" -->
- 我們準備使用[Aptitude](https://wiki.debian.org/Aptitude)安裝 TensorFlow Serving，因為此 Colab 在 Debian 環境中運行。我們將把這個`tensorflow-model-server`包添加到 Aptitude 知道的包列表中。請注意，我們以 root 身份運行。
- 最簡單的方式是以 Docker 佈署，您可以參考此[範例](https://www.tensorflow.org/tfx/serving/docker)。
<!-- #endregion -->

```python id="v2hF_ChoOrEd"
import sys
# We need sudo prefix if not on a Google Colab.
if 'google.colab' not in sys.modules:
  SUDO_IF_NEEDED = 'sudo'
else:
  SUDO_IF_NEEDED = ''
```

```python id="EWg9X2QHlbGS" colab={"base_uri": "https://localhost:8080/"} outputId="20d665da-489f-49f1-8539-d1c2a78bcf53"
# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo
# You would instead do:
# echo "deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \
# curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -

!echo "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal" | {SUDO_IF_NEEDED} tee /etc/apt/sources.list.d/tensorflow-serving.list && \
curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | {SUDO_IF_NEEDED} apt-key add -
!{SUDO_IF_NEEDED} apt update
```

<!-- #region id="W1ZVp_VOU7Wu" -->
### 安裝 TensorFlow Serving

<!-- #endregion -->

```python id="ygwa9AgRloYy" colab={"base_uri": "https://localhost:8080/"} outputId="062772d0-9db4-4ee3-dc84-4d735e55f9b1"
!{SUDO_IF_NEEDED} apt-get install tensorflow-model-server
```

<!-- #region id="wwlh8e-PKa4z" -->
### 啟動 TensorFlow Serving
<!-- #endregion -->

<!-- #region id="os0a4IeeKsQz" -->
加載後，我們可以開始使用 REST 發出推理請求，相關參數:

-   `rest_api_port`： REST 請求的 Port。
-   `model_name`：您將在 REST 請求的 URL 中使用它。
-   `model_base_path`：保存模型的目錄的路徑。
<!-- #endregion -->

```python id="aUgp3vUdU5GS"
os.environ["MODEL_DIR"] = MODEL_DIR
```

```bash id="kJDhHNJVnaLN" colab={"base_uri": "https://localhost:8080/"} outputId="53a28efa-c91e-41de-ba81-c7bab3124f6d" magic_args="--bg "
nohup tensorflow_model_server \
  --rest_api_port=8501 \
  --model_name=fashion_model \
  --model_base_path="${MODEL_DIR}" >server.log 2>&1

```

```python id="IxbeiOCUUs2z"
!tail server.log
```

<!-- #region id="7S4VXSBHLdNW" -->
## 以 Request 向 TensorFlow Serving 提出請求提出請求
<!-- #endregion -->

<!-- #region id="kPWZAVBdLtMC" -->
- 先以亂數查看 test data。
<!-- #endregion -->

```python id="Luqm_Jyff9iR" colab={"base_uri": "https://localhost:8080/", "height": 266} outputId="2fd413b4-684e-496f-dd0d-b3f3630f8a2c"
def show(idx, title):
  plt.figure()
  plt.imshow(test_images[idx].reshape(32,32,3))
  plt.axis('off')
  plt.title(f'{title}', fontdict={'size': 16})

import random
rando = random.randint(0,len(test_images)-1)
test_label_name = class_names[int(test_labels[rando])]
show(rando, f'An Example Image: {test_label_name}')
```

<!-- #region id="TKnEHeTrbh3L" -->
- 測試請求一批JSON。
<!-- #endregion -->

```python id="2dsD7KQG1m-R" colab={"base_uri": "https://localhost:8080/"} outputId="e1d6102d-9acf-410b-8c3a-0ceb3c2d5878"
import json
from pprint import pprint

data = json.dumps(
    {"signature_name": "serving_default", 
     "instances": test_images[0:3].tolist()}
     )
pprint(f'Data: {data[:50]} ... {data[len(data)-52:]}')
```

<!-- #region id="ReQd4QESIwXN" -->
### 發出 REST 請求
<!-- #endregion -->

<!-- #region id="AhEqF7fyOZsJ" -->
### 最新版本的 servable
<!-- #endregion -->

<!-- #region id="Xf7UyoiLOnj0" -->
- 以 POST 至 server，預設請求伺服器提供最新版次的內容。
<!-- #endregion -->

```python id="CgctjfjzQJl3"
# docs_infra: no_execute
!pip install -q requests
```

```python id="vGvFyuIzW6n6" colab={"base_uri": "https://localhost:8080/", "height": 266} outputId="422d820d-4fb4-474d-bb36-57fc24a5a089"
import requests
headers = {"content-type": "application/json"}
json_response = requests.post(
    'http://localhost:8501/v1/models/fashion_model:predict', 
    data=data, 
    headers=headers
    )

predictions = json.loads(json_response.text)['predictions']

show(0, 'The model thought this was a {} (class {}), and it was actually a {} (class {})'.format(
  class_names[np.argmax(predictions[0])], np.argmax(predictions[0]), class_names[int(test_labels[0])], test_labels[0]))
```

<!-- #region id="N9gdMLWmUaap" -->
### 指定特定版本服務
<!-- #endregion -->

<!-- #region id="nxoLxKIiUfRI" -->
- 以REST API 向伺服器請求指定版本`version = 1`。
<!-- #endregion -->

```python id="zRftRxeR1tZx" colab={"base_uri": "https://localhost:8080/", "height": 764} outputId="0925792a-7426-4aba-eb4e-78b0d403ec32"
# docs_infra: no_execute
version = 1

headers = {"content-type": "application/json"}
json_response = requests.post(
    f'http://localhost:8501/v1/models/fashion_model/versions/{version}:predict', 
    data=data, 
    headers=headers
    )

predictions = json.loads(json_response.text)['predictions']

for i in range(0,3):
  show(i, 'The model thought this was a {} (class {}), and it was actually a {} (class {})'.format(
    class_names[np.argmax(predictions[i])], np.argmax(predictions[i]), class_names[int(test_labels[i])], test_labels[i]))
```
