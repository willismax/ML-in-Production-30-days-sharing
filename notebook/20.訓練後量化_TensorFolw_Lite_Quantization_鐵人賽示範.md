---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.15.1
  kernelspec:
    display_name: Python 3
    name: python3
---

<!-- #region id="view-in-github" colab_type="text" -->
<a href="https://colab.research.google.com/github/willismax/ML-in-Production-30-days-sharing/blob/main/notebook/20.%E8%A8%93%E7%B7%B4%E5%BE%8C%E9%87%8F%E5%8C%96_TensorFolw_Lite_Quantization_%E9%90%B5%E4%BA%BA%E8%B3%BD%E7%A4%BA%E7%AF%84.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
<!-- #endregion -->

<!-- #region id="Jh7hg-rJ0PTq" -->
# TensorFolw Lite Quantization
<!-- #endregion -->

<!-- #region id="RSbYcJTVcn8V" -->
- 此為鐵人賽系列文示範文件，參考[TensorFlow Lite官方範例](https://www.tensorflow.org/lite/performance/post_training_quantization)修改而成。
- TF Lite 評估函數參考[來源](https://www.tensorflow.org/lite/performance/post_training_integer_quant_16x8)。
<!-- #endregion -->

```python id="WLBCobD7f1kD"
# 建立評估模型的dict
MODEL_SIZE = {}
ACCURACY = {}
```

```python id="YUXO0Br0ceK5"
import tensorflow as tf
import numpy as np
import os
```

<!-- #region id="STON2r7I0k0r" -->
## 建立基本模型
<!-- #endregion -->

<!-- #region id="NPzYuQQ20p0n" -->
- 模型採用`tf.keras.datasets.mnist`，用CNN進行建模。
<!-- #endregion -->

```python colab={"base_uri": "https://localhost:8080/"} id="6IXwf2IrdYGd" outputId="fe349226-8362-4057-bec2-ff698e560fa8"
# Load MNIST dataset
mnist = tf.keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Normalize the input image so that each pixel value is between 0 to 1.
train_images = train_images / 255.0
test_images = test_images / 255.0
```

```python id="9YdaJpyKeYFG"
def model_builder():

  keras = tf.keras

  model = keras.Sequential([
    keras.layers.InputLayer(input_shape=(28, 28)),
    keras.layers.Reshape(target_shape=(28, 28, 1)),
    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),
    keras.layers.MaxPooling2D(pool_size=(2, 2)),
    keras.layers.Flatten(),
    keras.layers.Dense(10, activation='softmax')
  ])

  return model
```

```python colab={"base_uri": "https://localhost:8080/"} id="nnjoU2Kvd7Qd" outputId="eb1e291f-830c-4e5a-89c2-84504ed87169"
baseline_model = model_builder()
baseline_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
    )

baseline_model.summary()
baseline_model.save_weights('baseline_weights.h5')

baseline_model.fit(train_images, train_labels, epochs=1, shuffle=False)
```

```python colab={"base_uri": "https://localhost:8080/"} id="s3WnmyYgfnc6" outputId="c157875b-a507-41f2-9099-18ccbb4cc96e"
# 儲存未量化模型
baseline_model.save('non_quantized.h5', include_optimizer=False)

# 評估模型並紀錄準確率
_, ACCURACY['baseline Keras model'] = baseline_model.evaluate(test_images, test_labels)

# 紀錄模型大小
MODEL_SIZE['baseline h5'] = os.path.getsize('non_quantized.h5')

```

```python colab={"base_uri": "https://localhost:8080/"} id="77vDwp0HBh22" outputId="cef227ac-6a7a-4752-a21f-974e7599f91d"
ACCURACY
```

```python colab={"base_uri": "https://localhost:8080/"} id="AnHDBKgUBlRi" outputId="e8afcda2-3c2d-4916-a418-a76ab895bfea"
MODEL_SIZE
```

<!-- #region id="IodMZad-iQOm" -->
## 轉為 TF Lite 格式
<!-- #endregion -->

<!-- #region id="6g1K6KTj4YuN" -->
- 轉為 TF Lite 使用的 `*.tflite`格式。
<!-- #endregion -->

```python colab={"base_uri": "https://localhost:8080/"} id="QfrTI1liiYgH" outputId="844dc4e7-918d-40e5-e35d-594c172b512c"
converter = tf.lite.TFLiteConverter.from_keras_model(baseline_model)

tflite_model = converter.convert()

with open('non_quantized.tflite', 'wb') as f:
    f.write(tflite_model)
```

<!-- #region id="oEThVNnk5kNC" -->
- 建立TF Lite 的評估模型準確率的函數，轉檔為tflite後需要特別撰寫，參考[官方範例](https://www.tensorflow.org/lite/performance/post_training_integer_quant_16x8#evaluate_the_models)。
<!-- #endregion -->

```python id="QlRgCXsG5iH_"
# A helper function to evaluate the TF Lite model using "test" dataset.
# from: https://www.tensorflow.org/lite/performance/post_training_integer_quant_16x8#evaluate_the_models
def evaluate_model(filemane):
  #Load the model into the interpreters
  interpreter = tf.lite.Interpreter(model_path=str(filemane))
  interpreter.allocate_tensors()

  input_index = interpreter.get_input_details()[0]["index"]
  output_index = interpreter.get_output_details()[0]["index"]

  # Run predictions on every image in the "test" dataset.
  prediction_digits = []
  for test_image in test_images:
    # Pre-processing: add batch dimension and convert to float32 to match with
    # the model's input data format.
    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)
    interpreter.set_tensor(input_index, test_image)

    # Run inference.
    interpreter.invoke()

    # Post-processing: remove batch dimension and find the digit with highest
    # probability.
    output = interpreter.tensor(output_index)
    digit = np.argmax(output()[0])
    prediction_digits.append(digit)

  # Compare prediction results with ground truth labels to calculate accuracy.
  accurate_count = 0
  for index in range(len(prediction_digits)):
    if prediction_digits[index] == test_labels[index]:
      accurate_count += 1
  accuracy = accurate_count * 1.0 / len(prediction_digits)

  return accuracy
```

<!-- #region id="BHuJvch68NgT" -->
- 精確值略有提升，模型大小略降
<!-- #endregion -->

```python colab={"base_uri": "https://localhost:8080/"} id="VbkooswO6rgs" outputId="664f2c36-c8d7-4129-9c00-7f280def351b"
ACCURACY['non quantized tflite'] = evaluate_model(filemane='non_quantized.tflite')
ACCURACY
```

```python colab={"base_uri": "https://localhost:8080/"} id="1-WyYeJrCXYk" outputId="1cb5c140-1cc0-4586-8655-c94f3fd6ebdd"
MODEL_SIZE['non quantized tflite'] = os.path.getsize('non_quantized.tflite')
MODEL_SIZE
```

<!-- #region id="snAqJgU6jo8t" -->
## 訓練後量化 Post-Training Quantization
<!-- #endregion -->

<!-- #region id="diSty0Ydtwct" -->
- 本範例示範訓練後量化之動態範圍量化 Dynamic range quantization 。
- 您也可以嘗試固定float8、float16量化。
<!-- #endregion -->

```python colab={"base_uri": "https://localhost:8080/"} id="UBod3nuQjvhA" outputId="74e49926-3563-49e5-f5fe-6a904b7fec89"
# Dynamic range quantization
converter = tf.lite.TFLiteConverter.from_keras_model(baseline_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open('post_training_quantized.tflite', 'wb') as f:
    f.write(tflite_model)
```

<!-- #region id="6dHOboGoCxE9" -->
- 模型大小下降許多，精準度略有提升
<!-- #endregion -->

```python colab={"base_uri": "https://localhost:8080/"} id="xdKYRUeE9TF3" outputId="3e680646-ac41-487b-8d03-8dad5315d042"
ACCURACY['post training quantized tflite'] = evaluate_model(filemane='post_training_quantized.tflite')
ACCURACY
```

```python colab={"base_uri": "https://localhost:8080/"} id="28TGVr0tBePK" outputId="be42848f-8909-464a-e09c-2059660f8d6c"
MODEL_SIZE['post training quantized tflite'] = os.path.getsize('post_training_quantized.tflite')
MODEL_SIZE
```

<!-- #region id="6m9zvJ_8qhVx" -->
## (選用)量化感知訓練 Quantization Aware Training
<!-- #endregion -->

<!-- #region id="dGSIJ4Lv_DMO" -->
- 當訓練後量化導致您的準確率下降多到無法接受，可以考慮在量化模型之前進行[量化感知訓練 Quantization Aware Training](https://www.tensorflow.org/model_optimization/guide/quantization/training)。
- 此方法為在訓練期間在模型中插入假量化節點來模擬精度損失，讓模型學會適應精度損失，以獲得更準確的預測。
- 需使用 `tensorflow_model_optimization` 模組，該模組提供 `quantize_model()` 完成任務。
- 調整後再量化可舒緩準確率下降的問題。
<!-- #endregion -->

```python colab={"base_uri": "https://localhost:8080/"} id="MBe08Yceqluq" outputId="dc50e8da-b66c-43cc-8213-4ad8df522b56"
!pip install tensorflow_model_optimization
```

<!-- #region id="cm6ZuC3y_2FL" -->
- 使用先前初步訓練的 'baseline_weights.h5' 模型權重進行優化。
- 模型增加了些假結點與 Layer。
<!-- #endregion -->

```python colab={"base_uri": "https://localhost:8080/"} id="uxFmeLJDqr-C" outputId="3976b8f1-237d-49f8-de61-e4dde087e949"
import tensorflow_model_optimization as tfmot

# method to quantize a Keras model
quantize_model = tfmot.quantization.keras.quantize_model

# Define the model architecture.
model_to_quantize = model_builder()

# Reinitialize weights with saved file
model_to_quantize.load_weights('baseline_weights.h5')

# Quantize the model
q_aware_model = quantize_model(model_to_quantize)

# `quantize_model` requires a recompile.
q_aware_model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

q_aware_model.summary()
```

```python id="b1Fk6As8YdOp"
q_aware_model.save('quantization_aware_non-quantized.h5', include_optimizer=False)
```

<!-- #region id="ftE33s3ZA3t1" -->
- 訓練經過感知訓練的模型，您可以自行調整 epochs。

<!-- #endregion -->

```python colab={"base_uri": "https://localhost:8080/"} id="yDlzVkgZrCGD" outputId="0b9f9bc3-493b-4c88-b3ad-34ccf086c5a3"
# Train the model
q_aware_model.fit(train_images, train_labels, epochs=10, shuffle=False)
```

```python id="gHtVzNXfrnas"
_, ACCURACY['quantization aware non-quantized'] = q_aware_model.evaluate(test_images, test_labels, verbose=0)
```

```python colab={"base_uri": "https://localhost:8080/"} id="nsEbxnfoBTFx" outputId="b3c42edd-e0f4-43e2-fe52-ce2400020943"
ACCURACY
```

```python colab={"base_uri": "https://localhost:8080/"} id="NYFr4oUrBTmI" outputId="a64d256e-dc1e-4648-8ca2-1dc6afa42ef9"
MODEL_SIZE['quantization aware non-quantized'] = os.path.getsize('quantization_aware_non-quantized.h5')
MODEL_SIZE
```
