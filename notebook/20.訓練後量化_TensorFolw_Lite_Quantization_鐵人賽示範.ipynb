{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "訓練後量化 TensorFolw Lite Quantization - 鐵人賽示範.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNkVgZgSTLl/EW8pFbKiUai",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willismax/ML-in-Production-30-days-sharing/blob/main/notebook/20.%E8%A8%93%E7%B7%B4%E5%BE%8C%E9%87%8F%E5%8C%96_TensorFolw_Lite_Quantization_%E9%90%B5%E4%BA%BA%E8%B3%BD%E7%A4%BA%E7%AF%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh7hg-rJ0PTq"
      },
      "source": [
        "# TensorFolw Lite Quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSbYcJTVcn8V"
      },
      "source": [
        "- 此為鐵人賽系列文示範文件，參考[TensorFlow Lite官方範例](https://www.tensorflow.org/lite/performance/post_training_quantization)修改而成。\n",
        "- TF Lite 評估函數參考[來源](https://www.tensorflow.org/lite/performance/post_training_integer_quant_16x8)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLBCobD7f1kD"
      },
      "source": [
        "# 建立評估模型的dict\n",
        "MODEL_SIZE = {}\n",
        "ACCURACY = {}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUXO0Br0ceK5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STON2r7I0k0r"
      },
      "source": [
        "## 建立基本模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPzYuQQ20p0n"
      },
      "source": [
        "- 模型採用`tf.keras.datasets.mnist`，用CNN進行建模。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IXwf2IrdYGd",
        "outputId": "fe349226-8362-4057-bec2-ff698e560fa8"
      },
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YdaJpyKeYFG"
      },
      "source": [
        "def model_builder():\n",
        "\n",
        "  keras = tf.keras\n",
        "\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "    keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnjoU2Kvd7Qd",
        "outputId": "eb1e291f-830c-4e5a-89c2-84504ed87169"
      },
      "source": [
        "baseline_model = model_builder()\n",
        "baseline_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "baseline_model.summary()\n",
        "baseline_model.save_weights('baseline_weights.h5')\n",
        "\n",
        "baseline_model.fit(train_images, train_labels, epochs=1, shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 12)        120       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 12)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2028)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20290     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,410\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.2800 - accuracy: 0.9227\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45c2badfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3WnmyYgfnc6",
        "outputId": "c157875b-a507-41f2-9099-18ccbb4cc96e"
      },
      "source": [
        "# 儲存未量化模型\n",
        "baseline_model.save('non_quantized.h5', include_optimizer=False)\n",
        "\n",
        "# 評估模型並紀錄準確率\n",
        "_, ACCURACY['baseline Keras model'] = baseline_model.evaluate(test_images, test_labels)\n",
        "\n",
        "# 紀錄模型大小\n",
        "MODEL_SIZE['baseline h5'] = os.path.getsize('non_quantized.h5')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1318 - accuracy: 0.9618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77vDwp0HBh22",
        "outputId": "cef227ac-6a7a-4752-a21f-974e7599f91d"
      },
      "source": [
        "ACCURACY"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline Keras model': 0.9617999792098999}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnHDBKgUBlRi",
        "outputId": "e8afcda2-3c2d-4916-a418-a76ab895bfea"
      },
      "source": [
        "MODEL_SIZE"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline h5': 99144}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IodMZad-iQOm"
      },
      "source": [
        "## 轉為 TF Lite 格式"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g1K6KTj4YuN"
      },
      "source": [
        "- 轉為 TF Lite 使用的 `*.tflite`格式。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfrTI1liiYgH",
        "outputId": "844dc4e7-918d-40e5-e35d-594c172b512c"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(baseline_model)\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('non_quantized.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpgr7ifpaq/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEThVNnk5kNC"
      },
      "source": [
        "- 建立TF Lite 的評估模型準確率的函數，轉檔為tflite後需要特別撰寫，參考[官方範例](https://www.tensorflow.org/lite/performance/post_training_integer_quant_16x8#evaluate_the_models)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlRgCXsG5iH_"
      },
      "source": [
        "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
        "# from: https://www.tensorflow.org/lite/performance/post_training_integer_quant_16x8#evaluate_the_models\n",
        "def evaluate_model(filemane):\n",
        "  #Load the model into the interpreters\n",
        "  interpreter = tf.lite.Interpreter(model_path=str(filemane))\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for test_image in test_images:\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  accurate_count = 0\n",
        "  for index in range(len(prediction_digits)):\n",
        "    if prediction_digits[index] == test_labels[index]:\n",
        "      accurate_count += 1\n",
        "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHuJvch68NgT"
      },
      "source": [
        "- 精確值略有提升，模型大小略降"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbkooswO6rgs",
        "outputId": "664f2c36-c8d7-4129-9c00-7f280def351b"
      },
      "source": [
        "ACCURACY['non quantized tflite'] = evaluate_model(filemane='non_quantized.tflite')\n",
        "ACCURACY"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline Keras model': 0.9617999792098999, 'non quantized tflite': 0.9618}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-WyYeJrCXYk",
        "outputId": "1cb5c140-1cc0-4586-8655-c94f3fd6ebdd"
      },
      "source": [
        "MODEL_SIZE['non quantized tflite'] = os.path.getsize('non_quantized.tflite')\n",
        "MODEL_SIZE"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline h5': 99144, 'non quantized tflite': 84728}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snAqJgU6jo8t"
      },
      "source": [
        "## 訓練後量化 Post-Training Quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diSty0Ydtwct"
      },
      "source": [
        "- 本範例示範訓練後量化之動態範圍量化 Dynamic range quantization 。\n",
        "- 您也可以嘗試固定float8、float16量化。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBod3nuQjvhA",
        "outputId": "74e49926-3563-49e5-f5fe-6a904b7fec89"
      },
      "source": [
        "# Dynamic range quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(baseline_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('post_training_quantized.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpsro84xmf/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpsro84xmf/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dHOboGoCxE9"
      },
      "source": [
        "- 模型大小下降許多，精準度略有提升"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdKYRUeE9TF3",
        "outputId": "3e680646-ac41-487b-8d03-8dad5315d042"
      },
      "source": [
        "ACCURACY['post training quantized tflite'] = evaluate_model(filemane='post_training_quantized.tflite')\n",
        "ACCURACY"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline Keras model': 0.9617999792098999,\n",
              " 'non quantized tflite': 0.9618,\n",
              " 'post training quantized tflite': 0.9618}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28TGVr0tBePK",
        "outputId": "be42848f-8909-464a-e09c-2059660f8d6c"
      },
      "source": [
        "MODEL_SIZE['post training quantized tflite'] = os.path.getsize('post_training_quantized.tflite')\n",
        "MODEL_SIZE"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline h5': 99144,\n",
              " 'non quantized tflite': 84728,\n",
              " 'post training quantized tflite': 24112}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m9zvJ_8qhVx"
      },
      "source": [
        "## (選用)量化感知訓練 Quantization Aware Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGSIJ4Lv_DMO"
      },
      "source": [
        "- 當訓練後量化導致您的準確率下降多到無法接受，可以考慮在量化模型之前進行[量化感知訓練 Quantization Aware Training](https://www.tensorflow.org/model_optimization/guide/quantization/training)。\n",
        "- 此方法為在訓練期間在模型中插入假量化節點來模擬精度損失，讓模型學會適應精度損失，以獲得更準確的預測。\n",
        "- 需使用 `tensorflow_model_optimization` 模組，該模組提供 `quantize_model()` 完成任務。\n",
        "- 調整後再量化可舒緩準確率下降的問題。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBe08Yceqluq",
        "outputId": "dc50e8da-b66c-43cc-8213-4ad8df522b56"
      },
      "source": [
        "!pip install tensorflow_model_optimization"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 153 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 174 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 184 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 204 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 215 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 225 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 235 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 237 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.7)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.21.6)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm6ZuC3y_2FL"
      },
      "source": [
        "- 使用先前初步訓練的 'baseline_weights.h5' 模型權重進行優化。\n",
        "- 模型增加了些假結點與 Layer。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxFmeLJDqr-C",
        "outputId": "3976b8f1-237d-49f8-de61-e4dde087e949"
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "# method to quantize a Keras model\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# Define the model architecture.\n",
        "model_to_quantize = model_builder()\n",
        "\n",
        "# Reinitialize weights with saved file\n",
        "model_to_quantize.load_weights('baseline_weights.h5')\n",
        "\n",
        "# Quantize the model\n",
        "q_aware_model = quantize_model(model_to_quantize)\n",
        "\n",
        "# `quantize_model` requires a recompile.\n",
        "q_aware_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "q_aware_model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer_1 (QuantizeL  (None, 28, 28)           3         \n",
            " ayer)                                                           \n",
            "                                                                 \n",
            " quant_reshape_2 (QuantizeWr  (None, 28, 28, 1)        1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_conv2d_2 (QuantizeWra  (None, 26, 26, 12)       147       \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_max_pooling2d_2 (Quan  (None, 13, 13, 12)       1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_flatten_2 (QuantizeWr  (None, 2028)             1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_dense_2 (QuantizeWrap  (None, 10)               20295     \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,448\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 38\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1Fk6As8YdOp"
      },
      "source": [
        "q_aware_model.save('quantization_aware_non-quantized.h5', include_optimizer=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftE33s3ZA3t1"
      },
      "source": [
        "- 訓練經過感知訓練的模型，您可以自行調整 epochs。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDlzVkgZrCGD",
        "outputId": "0b9f9bc3-493b-4c88-b3ad-34ccf086c5a3"
      },
      "source": [
        "# Train the model\n",
        "q_aware_model.fit(train_images, train_labels, epochs=10, shuffle=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.1097 - accuracy: 0.0992\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0801 - accuracy: 0.0992\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0659 - accuracy: 0.0991\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0568 - accuracy: 0.0991\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0502 - accuracy: 0.0990\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0450 - accuracy: 0.0989\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0407 - accuracy: 0.0989\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0369 - accuracy: 0.0989\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0336 - accuracy: 0.0989\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0306 - accuracy: 0.0990\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45c29fe850>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHtVzNXfrnas"
      },
      "source": [
        "_, ACCURACY['quantization aware non-quantized'] = q_aware_model.evaluate(test_images, test_labels, verbose=0)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsEbxnfoBTFx",
        "outputId": "b3c42edd-e0f4-43e2-fe52-ce2400020943"
      },
      "source": [
        "ACCURACY"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline Keras model': 0.9617999792098999,\n",
              " 'non quantized tflite': 0.9618,\n",
              " 'post training quantized tflite': 0.9618,\n",
              " 'quantization aware non-quantized': 0.09839999675750732}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYFr4oUrBTmI",
        "outputId": "a64d256e-dc1e-4648-8ca2-1dc6afa42ef9"
      },
      "source": [
        "MODEL_SIZE['quantization aware non-quantized'] = os.path.getsize('quantization_aware_non-quantized.h5')\n",
        "MODEL_SIZE"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline h5': 99144,\n",
              " 'non quantized tflite': 84728,\n",
              " 'post training quantized tflite': 24112,\n",
              " 'quantization aware non-quantized': 116472}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}