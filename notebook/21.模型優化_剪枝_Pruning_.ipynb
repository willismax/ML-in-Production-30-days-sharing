{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "模型優化 - 剪枝 Pruning .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNoJwRJ8eFrmiUaXG0mf8U/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willismax/ML-in-Production-30-days-sharing/blob/main/notebook/21.%E6%A8%A1%E5%9E%8B%E5%84%AA%E5%8C%96_%E5%89%AA%E6%9E%9D_Pruning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fioAy54REFpk"
      },
      "source": [
        "# 剪枝 Pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YV2WnBDdQwO"
      },
      "source": [
        "- 此為鐵人賽系列文示範文件，參考[TensorFlow Lite官方範例](https://www.tensorflow.org/lite/performance/post_training_quantization)修改而成。\n",
        "- TF Lite 評估函數參考[來源](https://www.tensorflow.org/lite/performance/post_training_integer_quant_16x8)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwvaMflTYNgo"
      },
      "source": [
        "- 剪枝 [Pruning](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)將無關緊要的權重歸零刪除歸零，在壓縮時能明顯縮小尺寸。\n",
        "- 經過剪枝且量化的模型可以縮小的原來1/10大小。\n",
        "- Tensorflow 模型優化模組的`prune_low_magnitude()`，可以將Keras模型在訓練期間將影響較小的權重修剪歸零。\n",
        "- 在本範例中，您將使用與示範[訓練後量化](https://colab.research.google.com/drive/1ukgVrMdtWjpReIygWHJ7-Lcw61Lv5kAO)相同的基準模型進行優化。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eLMjw2wdKLg"
      },
      "source": [
        "# 建立評估模型的dict\n",
        "MODEL_SIZE = {}\n",
        "ACCURACY = {}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hlLho0edo60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4f479a-ba33-4874-84ca-316919ea21dc"
      },
      "source": [
        "!pip install -q -U tensorflow_model_optimization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 237 kB 5.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FWoN81ud8Pl"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7irjO4VkU5U"
      },
      "source": [
        "## 建立基本模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBpUaNvRkYdI"
      },
      "source": [
        "- 模型採用`tf.keras.datasets.mnist`，用CNN進行建模。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6rKXfkpd6lN",
        "outputId": "771894ab-4bdb-4bc9-ef39-9ea97ab51833"
      },
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YdaJpyKeYFG"
      },
      "source": [
        "def model_builder():\n",
        "\n",
        "  keras = tf.keras\n",
        "\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "    keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnjoU2Kvd7Qd",
        "outputId": "40d0a807-7239-44f8-f937-32498009505e"
      },
      "source": [
        "baseline_model = model_builder()\n",
        "baseline_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "baseline_model.summary()\n",
        "baseline_model.save_weights('baseline_weights.h5')\n",
        "\n",
        "baseline_model.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    epochs=1, \n",
        "    shuffle=False\n",
        "    )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 12)        120       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 12)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2028)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20290     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,410\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.3040 - accuracy: 0.9153\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f948c96bb10>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acWJOg5vkeka",
        "outputId": "064f6562-7b21-4b7d-ef0f-cb905e161c64"
      },
      "source": [
        "# 儲存未量化模型\n",
        "baseline_model.save('non_pruned.h5', include_optimizer=False)\n",
        "\n",
        "# 評估模型並紀錄準確率\n",
        "_, ACCURACY['baseline Keras model'] = baseline_model.evaluate(test_images, test_labels)\n",
        "\n",
        "# 紀錄模型大小\n",
        "MODEL_SIZE['baseline h5'] = os.path.getsize('non_pruned.h5')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1500 - accuracy: 0.9544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14zo30Eqke6R",
        "outputId": "53c83dad-99cf-42c1-ec4a-1fc83e52dadd"
      },
      "source": [
        "ACCURACY"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline Keras model': 0.9544000029563904}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGT8PhHXtTiz",
        "outputId": "7499f416-7dcc-4fc1-be22-55d5f2df8f98"
      },
      "source": [
        "MODEL_SIZE"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline h5': 99144}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSBeouK9tmCs"
      },
      "source": [
        "## 使用剪枝調整模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J0MhxPbhyJN"
      },
      "source": [
        "- 進行剪枝，另外因為剪枝模型方法有增加一層包裝層，摘要顯示的參數會增加。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpqizJsKYPBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "312c7436-e40d-45cd-86bc-9d67023058d3"
      },
      "source": [
        "# Get the pruning method\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = train_images.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define pruning schedule.\n",
        "pruning_params = {\n",
        "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
        "        initial_sparsity=0.50,\n",
        "        final_sparsity=0.80,\n",
        "        begin_step=0,\n",
        "        end_step=end_step)\n",
        "    }\n",
        "\n",
        "# Pass in the trained baseline model\n",
        "model_for_pruning = prune_low_magnitude(\n",
        "    baseline_model, \n",
        "    **pruning_params\n",
        "    )\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:238: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  trainable=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_reshape  (None, 28, 28, 1)        1         \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d   (None, 26, 26, 12)       230       \n",
            " (PruneLowMagnitude)                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_max_poo  (None, 13, 13, 12)       1         \n",
            " ling2d (PruneLowMagnitude)                                      \n",
            "                                                                 \n",
            " prune_low_magnitude_flatten  (None, 2028)             1         \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_dense (  (None, 10)               40572     \n",
            " PruneLowMagnitude)                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40,805\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 20,395\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:218: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  aggregation=tf.VariableAggregation.MEAN)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:225: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  aggregation=tf.VariableAggregation.MEAN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgmHaZI6fip_"
      },
      "source": [
        "- 查看模型中某一層的權重。\n",
        "  - 剪枝前，有些微弱的權重。\n",
        "  - 剪枝後，其中許多將被清零。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5ekdEBigB5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "718edf8a-5213-4677-8ede-27ee6b3d6587"
      },
      "source": [
        "# 剪枝前的模型權重\n",
        "model_for_pruning.weights[1]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 12) dtype=float32, numpy=\n",
              "array([[[[-1.38251856e-01,  5.87693863e-02,  6.17338836e-01,\n",
              "           1.08750060e-01,  2.33612686e-01,  2.05966040e-01,\n",
              "           3.54602486e-01, -6.88196719e-01,  2.98866808e-01,\n",
              "          -1.55828863e-01, -1.81033790e-01,  2.16924008e-02]],\n",
              "\n",
              "        [[ 2.13686824e-01,  2.14811400e-01, -7.14632332e-01,\n",
              "          -1.17491134e-01,  3.92742068e-01,  2.02936888e-01,\n",
              "          -1.47854397e-02, -3.02368641e-01,  2.53374457e-01,\n",
              "          -6.78731978e-01,  2.45914683e-01,  5.62961176e-02]],\n",
              "\n",
              "        [[ 2.69658089e-01,  8.45840871e-02, -1.61144391e-01,\n",
              "           9.61077958e-02, -7.01730371e-01,  4.82204482e-02,\n",
              "          -3.08770835e-01, -9.93704051e-02,  6.57210171e-01,\n",
              "          -6.09114468e-01,  2.19620198e-01,  1.99704468e-01]]],\n",
              "\n",
              "\n",
              "       [[[-6.87311813e-02,  7.84165338e-02,  2.05764458e-01,\n",
              "           6.11244179e-02,  3.80745620e-01, -1.08126715e-01,\n",
              "           1.98725969e-01,  1.38404980e-01,  1.14110354e-02,\n",
              "           2.87296832e-01,  1.12220854e-01, -2.08614245e-02]],\n",
              "\n",
              "        [[ 2.32565984e-01,  2.63955891e-01, -1.03601289e+00,\n",
              "           1.33779749e-01,  4.41550732e-01,  8.09986740e-02,\n",
              "           3.33155036e-01,  2.01173067e-01, -1.58073530e-01,\n",
              "           1.53586239e-01,  4.76924411e-04,  2.62571156e-01]],\n",
              "\n",
              "        [[ 2.45618790e-01, -4.40435410e-02,  6.03120863e-01,\n",
              "           1.75590649e-01, -8.46487164e-01, -4.08586822e-02,\n",
              "           2.08683908e-01,  1.31300896e-01, -1.65983737e-01,\n",
              "          -3.03816378e-01,  2.09501594e-01,  1.49180025e-01]]],\n",
              "\n",
              "\n",
              "       [[[ 1.81603000e-01,  2.86728926e-02, -3.30129147e-01,\n",
              "           1.95746094e-01,  3.70084524e-01,  1.89021751e-01,\n",
              "           5.53700840e-03,  9.04731103e-04, -2.80269802e-01,\n",
              "           5.11834919e-01, -2.07357347e-01,  9.10703167e-02]],\n",
              "\n",
              "        [[ 9.66148451e-02,  1.51935756e-01, -2.44250402e-01,\n",
              "           1.63966864e-01, -3.41881335e-01,  1.70979440e-01,\n",
              "          -6.88327029e-02,  2.75808483e-01, -3.88703942e-01,\n",
              "           3.12805921e-01,  2.00992048e-01,  3.10923219e-01]],\n",
              "\n",
              "        [[ 1.17742762e-01,  2.81568319e-01,  5.06372452e-01,\n",
              "           4.83777374e-02, -6.46419108e-01, -1.72543749e-02,\n",
              "           1.69632956e-01,  1.75053343e-01, -5.09994090e-01,\n",
              "           4.22961771e-01,  2.41271481e-01, -1.63181320e-01]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpL0rLsMO0Fo"
      },
      "source": [
        "- 重新訓練模型。並在 Callback 增加`tfmot.sparsity.keras.UpdatePruningStep()`參數。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUCz6PL371Bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e648d669-67f8-408f-e5a4-2f6731dd47e0"
      },
      "source": [
        "# Callback to update pruning wrappers at each step\n",
        "callbacks=[tfmot.sparsity.keras.UpdatePruningStep()]\n",
        "\n",
        "# Train and prune the model\n",
        "model_for_pruning.fit(\n",
        "    train_images, \n",
        "    train_labels,\n",
        "    epochs=epochs, \n",
        "    validation_split=validation_split,\n",
        "    callbacks=callbacks\n",
        "    )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1688/1688 [==============================] - 22s 12ms/step - loss: 0.1640 - accuracy: 0.9569 - val_loss: 0.1084 - val_accuracy: 0.9717\n",
            "Epoch 2/2\n",
            "1688/1688 [==============================] - 19s 11ms/step - loss: 0.1232 - accuracy: 0.9631 - val_loss: 0.0985 - val_accuracy: 0.9752\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f94910e1290>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pSmR6iHPPOH"
      },
      "source": [
        "- 重新訓練後已修剪，觀察同一層的權重變化，許多不重要的權重已歸零。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOK4TidJhXpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88aef84-2029-4b0f-b1f2-9b4dbd12595c"
      },
      "source": [
        "# 剪枝後的模型權重\n",
        "model_for_pruning.weights[1]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 12) dtype=float32, numpy=\n",
              "array([[[[ 0.        ,  0.        ,  0.83686227, -0.        ,\n",
              "          -0.        ,  0.        ,  0.84368485, -1.1801223 ,\n",
              "          -0.        ,  0.        , -0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  0.        , -1.202781  ,  0.        ,\n",
              "           0.7022678 , -0.        , -0.        , -0.        ,\n",
              "          -0.        , -0.9440731 ,  0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  0.        , -0.        , -0.        ,\n",
              "          -1.0991509 , -0.        , -0.        , -0.        ,\n",
              "           1.1029274 , -1.0059565 ,  0.        ,  0.        ]]],\n",
              "\n",
              "\n",
              "       [[[ 0.        ,  0.        ,  0.        , -0.        ,\n",
              "           0.84900624,  0.        ,  0.        ,  0.        ,\n",
              "          -0.        ,  0.        , -0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  0.        , -1.5815098 , -0.        ,\n",
              "           0.668169  , -0.        ,  0.9408827 ,  0.        ,\n",
              "          -0.        ,  0.        ,  0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  0.        ,  0.9774921 , -0.        ,\n",
              "          -1.4214759 , -0.        , -0.        ,  0.        ,\n",
              "          -0.        ,  0.        ,  0.        ,  0.        ]]],\n",
              "\n",
              "\n",
              "       [[[ 0.        ,  0.        ,  0.        , -0.        ,\n",
              "           0.        , -0.        ,  0.        ,  0.        ,\n",
              "          -0.        ,  1.1311644 , -0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  0.        ,  0.        , -0.        ,\n",
              "          -0.        , -0.        ,  0.        ,  0.8030754 ,\n",
              "          -0.        ,  0.        ,  0.        ,  0.884976  ]],\n",
              "\n",
              "        [[ 0.        ,  0.        ,  0.67732257, -0.        ,\n",
              "          -1.0991007 , -0.        , -0.        ,  0.        ,\n",
              "          -1.2042779 ,  0.6830643 ,  0.        , -0.        ]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8o0ukVLmV4o"
      },
      "source": [
        "### 剪枝後移除包裝層\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVo5HSttPq5D"
      },
      "source": [
        "- 剪枝之後，您可以用[`tfmot.sparsity.keras.strip_pruning()`](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/strip_pruning)刪除包裝層以具有與基線模型相同的層和參數。\n",
        "- 此方法也有助於保存模型並導出為`*.tflite`檔案格式。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbfLhZv68vwc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c53618-ec3e-403b-f1ff-a28003861df9"
      },
      "source": [
        "# Remove pruning wrappers\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "model_for_export    .summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 12)        120       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 12)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2028)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20290     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,410\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UitndoqKQd-G"
      },
      "source": [
        "- 因為包裝器已被移除，相同的模型權重，已移置索引[0]。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG6-aF9yiraG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef58054c-64aa-4593-f02e-790f087cb8a8"
      },
      "source": [
        "model_for_export.weights[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 12) dtype=float32, numpy=\n",
              "array([[[[ 0.        ,  0.        ,  0.83686227, -0.        ,\n",
              "          -0.        ,  0.        ,  0.84368485, -1.1801223 ,\n",
              "          -0.        ,  0.        , -0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  0.        , -1.202781  ,  0.        ,\n",
              "           0.7022678 , -0.        , -0.        , -0.        ,\n",
              "          -0.        , -0.9440731 ,  0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  0.        , -0.        , -0.        ,\n",
              "          -1.0991509 , -0.        , -0.        , -0.        ,\n",
              "           1.1029274 , -1.0059565 ,  0.        ,  0.        ]]],\n",
              "\n",
              "\n",
              "       [[[ 0.        ,  0.        ,  0.        , -0.        ,\n",
              "           0.84900624,  0.        ,  0.        ,  0.        ,\n",
              "          -0.        ,  0.        , -0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  0.        , -1.5815098 , -0.        ,\n",
              "           0.668169  , -0.        ,  0.9408827 ,  0.        ,\n",
              "          -0.        ,  0.        ,  0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  0.        ,  0.9774921 , -0.        ,\n",
              "          -1.4214759 , -0.        , -0.        ,  0.        ,\n",
              "          -0.        ,  0.        ,  0.        ,  0.        ]]],\n",
              "\n",
              "\n",
              "       [[[ 0.        ,  0.        ,  0.        , -0.        ,\n",
              "           0.        , -0.        ,  0.        ,  0.        ,\n",
              "          -0.        ,  1.1311644 , -0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  0.        ,  0.        , -0.        ,\n",
              "          -0.        , -0.        ,  0.        ,  0.8030754 ,\n",
              "          -0.        ,  0.        ,  0.        ,  0.884976  ]],\n",
              "\n",
              "        [[ 0.        ,  0.        ,  0.67732257, -0.        ,\n",
              "          -1.0991007 , -0.        , -0.        ,  0.        ,\n",
              "          -1.2042779 ,  0.6830643 ,  0.        , -0.        ]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teMWEkNFQvVk"
      },
      "source": [
        "- 將剪枝後的檔案保存為`*.h5`，此時模型與修剪前大小相同。但一旦壓縮模型則改善\n",
        "相當明顯。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjjDMqJCTjqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c403601e-bb12-4d0d-9fb3-4f187a6ec4a4"
      },
      "source": [
        "# Save Keras model\n",
        "model_for_export.save('pruned_model.h5', include_optimizer=False)\n",
        "\n",
        "# Get uncompressed model size of baseline and pruned models\n",
        "MODEL_SIZE['pruned non quantized h5'] = os.path.getsize('pruned_model.h5')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywvDyXjfGW8s",
        "outputId": "df06ddbc-92c1-4b9c-89b5-116856d4078c"
      },
      "source": [
        "MODEL_SIZE"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline h5': 99144, 'pruned non quantized h5': 99144}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwlnW7KWeVxl"
      },
      "source": [
        "## 模型壓縮3倍術"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBvVeyAiRpzi"
      },
      "source": [
        "- 剪枝後的模型再壓縮。\n",
        "- 壓縮後檔案大小約為原本1/3，這是因為剪枝後歸零的權重可以更有效的壓縮。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlUv5yXHSEOr"
      },
      "source": [
        "import tempfile\n",
        "import zipfile\n",
        "\n",
        "_, zipped_file = tempfile.mkstemp('.zip')\n",
        "with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write('pruned_model.h5')\n",
        "\n",
        "\n",
        "MODEL_SIZE['pruned non quantized h5'] = os.path.getsize('pruned_model.h5')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWQ_AgiX_yiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd42131a-6009-4c92-b4c7-8445ed12dbd6"
      },
      "source": [
        "MODEL_SIZE"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline h5': 99144, 'pruned non quantized h5': 99144}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ddwmhlAX4ug"
      },
      "source": [
        "## 模型壓縮10倍術\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fp8d4t-dgnj"
      },
      "source": [
        "- 現在嘗試將已精剪枝後的模型再量化。\n",
        "- 量化原本就會縮小約4倍，將剪枝模型壓縮後再量化，與基本模型相比，這使模型減少了約 10 倍。\n",
        "- 小10倍精度還能維持水準。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTK3Ulja-dUy",
        "outputId": "2c80a8f1-cae7-45b8-f83d-168e1fb3a8eb"
      },
      "source": [
        "# 剪枝壓縮後再量化模型\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(baseline_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('pruned_quantized.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp8lwhbr77/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIY6n9XWCvt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb4e900-c8cb-4003-f86e-d643e63ad9cc"
      },
      "source": [
        "MODEL_SIZE['pruned quantized tflite'] = os.path.getsize('pruned_quantized.tflite')\n",
        "MODEL_SIZE\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline h5': 99144,\n",
              " 'pruned non quantized h5': 99144,\n",
              " 'pruned quantized tflite': 24112}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4ytiH3ynIid"
      },
      "source": [
        "- 即便小十倍，精度還維持原本水準。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d4MY-ozBRRd"
      },
      "source": [
        "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
        "# from: https://www.tensorflow.org/lite/performance/post_training_integer_quant_16x8#evaluate_the_models\n",
        "def evaluate_model(filemane):\n",
        "  #Load the model into the interpreters\n",
        "  interpreter = tf.lite.Interpreter(model_path=str(filemane))\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for test_image in test_images:\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  accurate_count = 0\n",
        "  for index in range(len(prediction_digits)):\n",
        "    if prediction_digits[index] == test_labels[index]:\n",
        "      accurate_count += 1\n",
        "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZBAdJmuWN0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2324bef-79bc-45d0-ddf5-19a279bcc55a"
      },
      "source": [
        "# Get accuracy of pruned Keras and TF Lite models\n",
        "\n",
        "_, ACCURACY['pruned model h5'] = model_for_pruning.evaluate(test_images, test_labels)\n",
        "ACCURACY['pruned and quantized tflite'] = evaluate_model('pruned_quantized.tflite')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1097 - accuracy: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfxlrwVJfLlt"
      },
      "source": [
        "## 成果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bamu10fzA0R_",
        "outputId": "0475f49c-b177-41a7-a76a-3578ea7e3bf2"
      },
      "source": [
        "ACCURACY"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline Keras model': 0.9544000029563904,\n",
              " 'pruned and quantized tflite': 0.9663,\n",
              " 'pruned model h5': 0.96670001745224}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPJh07O1fOwh",
        "outputId": "d7b22637-6b35-4e50-bec5-cc353d9de4ba"
      },
      "source": [
        "MODEL_SIZE"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline h5': 99144,\n",
              " 'pruned non quantized h5': 99144,\n",
              " 'pruned quantized tflite': 24112}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDVfBxbVfSiz"
      },
      "source": [
        "## 參考\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ9OnRQDfYQD"
      },
      "source": [
        "- [TensorFlow Lite官方範例](https://www.tensorflow.org/lite/performance/post_training_quantization)。\n",
        "- TF Lite 評估函數參考[來源](https://www.tensorflow.org/lite/performance/post_training_integer_quant_16x8)。"
      ]
    }
  ]
}